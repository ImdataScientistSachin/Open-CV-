{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a2d03a-9383-4f19-af94-7d2a4031b3c0",
   "metadata": {},
   "source": [
    "## Image Stitching using Open CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22099c-e7f2-466b-a462-4f11aa51e057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f4497e1-0f2f-4bb6-89c4-6744bd2bf876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfd13023-40d7-4aed-ae7e-e842a1abec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_image_suitable(img):\n",
    "    \"\"\"\n",
    "    Check if the image has enough features for stitching.\n",
    "    Returns True if sufficient keypoints are detected.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints = orb.detect(gray, None)\n",
    "    return len(keypoints) > 200  # Empirical threshold\n",
    "\n",
    "def downscale_image(img, max_dim=1200):\n",
    "    \"\"\"\n",
    "    Downscale large images for performance.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > max_dim:\n",
    "        scale = max_dim / max(h, w)\n",
    "        img = cv2.resize(img, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def resize_images_to_minimum(images):\n",
    "    \"\"\"\n",
    "    Resize all images to the smallest width and height among them.\n",
    "    This keeps them consistent for stitching or concatenation.\n",
    "    \"\"\"\n",
    "    min_height = min(img.shape[0] for img in images)\n",
    "    min_width = min(img.shape[1] for img in images)\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        resized = cv2.resize(img, (min_width, min_height), interpolation=cv2.INTER_AREA)\n",
    "        resized_images.append(resized)\n",
    "    return resized_images\n",
    "\n",
    "def concat_images(img1, img2, direction='horizontal'):\n",
    "    \"\"\"\n",
    "    Concatenate two images in the specified direction.\n",
    "    \"\"\"\n",
    "    if direction == 'horizontal':\n",
    "        return cv2.hconcat([img1, img2])\n",
    "    else:\n",
    "        return cv2.vconcat([img1, img2])\n",
    "\n",
    "def estimate_and_align(img1, img2, search_width=200):\n",
    "    \"\"\"\n",
    "    Attempts to find the best horizontal overlap between img1 and img2 using template matching.\n",
    "    Returns a stitched image with estimated overlap.\n",
    "    \"\"\"\n",
    "    # Use the right edge of img1 as template\n",
    "    template = img1[:, -search_width:]\n",
    "    res = cv2.matchTemplate(img2, template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(res)\n",
    "    x_offset = max_loc[0]\n",
    "    # Align images based on estimated offset\n",
    "    img2_aligned = img2[:, x_offset:]\n",
    "    result = np.hstack([img1, img2_aligned])\n",
    "    return result\n",
    "\n",
    "class StitcherApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Image Stitching with OpenCV\")\n",
    "        self.image_paths = []\n",
    "        self.panel = tk.Label(root)\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        tk.Button(self.root, text=\"Open 2 Images\", command=self.open_files).pack(pady=10)\n",
    "        tk.Button(self.root, text=\"Stitch Images\", command=self.stitch_images).pack(pady=10)\n",
    "        self.panel.pack(padx=10, pady=10)\n",
    "\n",
    "    def open_files(self):\n",
    "        \"\"\"\n",
    "        Open a file dialog to select exactly 2 different images.\n",
    "        Ensures the files are not the same and handles path normalization robustly.\n",
    "        \"\"\"\n",
    "        files = filedialog.askopenfilenames(\n",
    "            title='Select 2 Different Images',\n",
    "            filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff *.tif\")]\n",
    "        )\n",
    "        if len(files) != 2:\n",
    "            messagebox.showerror(\"Error\", \"Please select exactly two different images.\")\n",
    "            return\n",
    "\n",
    "        # Normalize and compare absolute paths (case-insensitive for Windows)\n",
    "        file1 = os.path.normcase(os.path.abspath(files[0]))\n",
    "        file2 = os.path.normcase(os.path.abspath(files[1]))\n",
    "\n",
    "        if file1 == file2:\n",
    "            messagebox.showerror(\"Error\", \"You have selected the same image twice. Please select two different images.\")\n",
    "            return\n",
    "\n",
    "        self.image_paths = [file1, file2]\n",
    "        messagebox.showinfo(\"Success\", \"Selected 2 different images.\")\n",
    "\n",
    "    def stitch_images(self):\n",
    "        \"\"\"\n",
    "        Load, validate, resize, and stitch the selected images.\n",
    "        If stitching fails due to insufficient overlap, try template matching alignment, else concatenate.\n",
    "        \"\"\"\n",
    "        if len(self.image_paths) != 2:\n",
    "            messagebox.showerror(\"Error\", \"Please select exactly two images before stitching.\")\n",
    "            return\n",
    "\n",
    "        images = []\n",
    "        for path in self.image_paths:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                messagebox.showerror(\"Error\", f\"Could not read image {path}\")\n",
    "                return\n",
    "            img = downscale_image(img)\n",
    "            if not is_image_suitable(img):\n",
    "                messagebox.showerror(\n",
    "                    \"Error\",\n",
    "                    f\"Image '{os.path.basename(path)}' lacks sufficient features for stitching.\\n\"\n",
    "                    \"Try using images with more texture or detail.\"\n",
    "                )\n",
    "                return\n",
    "            images.append(img)\n",
    "\n",
    "        # Resize both images to the smallest dimensions\n",
    "        images = resize_images_to_minimum(images)\n",
    "        self.handle_overlap_and_stitch(images)\n",
    "\n",
    "    def handle_overlap_and_stitch(self, images, overlap_px=100):\n",
    "        \"\"\"\n",
    "        Try OpenCV's stitcher. If it fails, try template matching alignment. If that fails, concatenate.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            stitcher = cv2.Stitcher_create(cv2.Stitcher_PANORAMA)\n",
    "        except AttributeError:\n",
    "            stitcher = cv2.createStitcher(False)\n",
    "        status, pano = stitcher.stitch(images)\n",
    "        if status == cv2.Stitcher_OK:\n",
    "            self.display_image(pano)\n",
    "            messagebox.showinfo(\"Success\", \"Images stitched successfully.\")\n",
    "            return\n",
    "\n",
    "        # If stitching fails, try estimated alignment (template matching)\n",
    "        try:\n",
    "            aligned = estimate_and_align(images[0], images[1], search_width=overlap_px)\n",
    "            self.display_image(aligned)\n",
    "            messagebox.showwarning(\n",
    "                \"Estimated Alignment\",\n",
    "                \"Stitching failed (insufficient overlap/features), so images were aligned using template matching.\\n\"\n",
    "                \"For best results, use images with 30â€“50% overlap and rich, unique textures.\"\n",
    "            )\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(\"Estimated alignment failed:\", e)\n",
    "\n",
    "        # Fallback: Concatenation\n",
    "        concat = concat_images(images[0], images[1], direction='horizontal')\n",
    "        self.display_image(concat)\n",
    "        messagebox.showwarning(\n",
    "            \"Concatenation\",\n",
    "            \"Stitching and alignment failed. Images were concatenated as a fallback.\"\n",
    "        )\n",
    "\n",
    "    def display_image(self, cv_image):\n",
    "        \"\"\"Display the stitched or concatenated image in the Tkinter panel.\"\"\"\n",
    "        cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(cv_image_rgb)\n",
    "        imgtk = ImageTk.PhotoImage(image=pil_image)\n",
    "        self.panel.config(image=imgtk)\n",
    "        self.panel.image = imgtk  # Prevent garbage collection\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = StitcherApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a24b87-fd07-46d5-98ed-a00572f340c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9ffb8-4f62-4d1f-9c76-2d9abac54381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
